import gradio as gr
import time
import random
from my_knowledge_rag_qa_llm_log.RAG.worker.utils import *
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain.prompts import PromptTemplate

# ç³»ç»ŸPROMPT
PROMPT = PromptTemplate.from_template("""æ ¹æ®ä¸‹é¢çš„ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰å†…å®¹å›ç­”é—®é¢˜ã€‚
å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±å›ç­”ä¸çŸ¥é“ï¼Œä¸è¦è¯•å›¾ç¼–é€ ç­”æ¡ˆã€‚
ç­”æ¡ˆæœ€å¤š3å¥è¯ï¼Œä¿æŒç­”æ¡ˆç®€æ´ã€‚
{context}
é—®é¢˜ï¼š{question}
""")
# åŠ è½½embeddingæ¨¡å‹
embeddings = load_embedding_model()
# åŠ è½½æ•°æ®åº“
if not os.path.exists('VectorStore'):
    documents = load_documents()
    db = store_chroma(documents, embeddings)
else:
    db = Chroma(persist_directory='VectorStore', embedding_function=embeddings)

retriever = db.as_retriever()
llm = get_llm()
rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | PROMPT
        | llm
        | StrOutputParser()
)


def add_text(history, text):
    history = history + [(text, None)]
    return history, gr.Textbox(value="", interactive=True)


def add_file(history, file):
    history = history + [((file.name,), None)]
    return history


def add_file2(history, file):
    """
    ä¸Šä¼ æ–‡ä»¶åçš„å›è°ƒå‡½æ•°ï¼Œå°†ä¸Šä¼ çš„æ–‡ä»¶å‘é‡åŒ–å­˜å…¥æ•°æ®åº“
    :param history:
    :param file:
    :return:
    """
    directory = os.path.dirname(file.name)
    documents = load_documents(directory)
    db = store_chroma(documents, embeddings)
    retriever = db.as_retriever()
    global rag_chain
    rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | PROMPT
            | llm
            | StrOutputParser()
    )
    history = history + [((file.name,), None)]
    return history


def bot(history):
    message = history[-1][0]
    # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æ˜¯ä¸€ä¸ªå…ƒç»„ç±»å‹ï¼Œé€šå¸¸è¿™ç§æƒ…å†µä¸‹ä»£è¡¨æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œå› ä¸ºä¸Šä¼ æˆåŠŸåå¾€å¾€è¿”å›çš„æ˜¯å…ƒç»„æ•°æ®ï¼Œæ¯”å¦‚ (æ–‡ä»¶å, æ–‡ä»¶å¤§å°)
    if isinstance(message, tuple):
        response = "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ"
    else:
        # response = rag_chain.invoke(history)
        response = random.choice(["How are you?", "I love you", "I'm very hungry"])
    history[-1][1] = ""
    for character in response:
        history[-1][1] += character
        time.sleep(0.05)
        yield history


with gr.Blocks() as demo:
    chatbot = gr.Chatbot(
        [],
        elem_id="chatbot",
        bubble_full_width=False,
        avatar_images=(None, (os.path.join(os.path.dirname(__file__), "imgs", "avatar.jpg"))),
    )

    with gr.Row():
        btn = gr.UploadButton("ğŸ“", scale=3, file_types=["text"])
        txt = gr.Textbox(
            scale=20,
            show_label=False,
            label="chatInfo",
            placeholder="è¾“å…¥æ–‡å­—",
            container=False,
        )
        btn_submit = gr.Button(scale=6, value="Generate", variant="primary")
        btn_clear = gr.Button(scale=2, value="Clear", variant="secondary")

        # ä¸Šä¼ æ–‡ä»¶å¤„ç†é€»è¾‘
        file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(
            bot, chatbot, chatbot, api_name="bot_file_response"
        )
        # å‘é€æ–‡æœ¬ ç‚¹å‡»æŒ‰é’® å¤„ç†é€»è¾‘
        btn_submit.click(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(
            bot, chatbot, chatbot, api_name="bot_text_response"
        )
        # å‘é€æ–‡æœ¬ enter å¤„ç†é€»è¾‘
        txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(
            bot, chatbot, chatbot, api_name="bot_text_response"
        )
        # æ¸…é™¤å†å²å¤„ç†é€»è¾‘
        btn_clear.click(lambda: None, None, chatbot, queue=False)

if __name__ == '__main__':
    # é€šå¸¸ï¼Œåœ¨ä½¿ç”¨ gr.Blocks()åˆ›å»ºUIç»„ä»¶æ—¶ï¼Œè¿™äº›ç»„ä»¶å°†ä¼šè¢«æ·»åŠ åˆ°ä¸€ä¸ªé˜Ÿåˆ—ä¸­(å°†å®šä¹‰çš„UIç»„ä»¶æ·»åŠ åˆ°å¯è§†åŒ–ç•Œé¢çš„é˜Ÿåˆ—ä¸­)
    demo.queue()
    demo.launch(share=False)
